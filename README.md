## Neural Network from Scratch using MNIST Dataset

**Project Overview**

This project is a neural network built entirely from scratch using only NumPy, without relying on high-level libraries like Keras or TensorFlow. The model is trained on the MNIST image dataset, which contains 60,000 training images and 10,000 test images of handwritten digits (0-9). The primary objective of this project was to deepen my understanding of neural networks by implementing each component manually, including forward propagation, loss computation, backpropagation, and parameter updates.

Motivation

Building a neural network from scratch helps to solidify the mathematical concepts behind deep learning. Implementing forward and backward propagation manually provides a deeper understanding of how gradients are calculated and how weights are updated.

**Project Features**

* Pure NumPy Implementation: No high-level deep learning libraries were used.

* Training on MNIST Dataset: The model is trained on grayscale images (28x28 pixels) representing digits 0-9.

* Manual Forward and Backward Propagation: Implemented from scratch for a better conceptual grasp.

* Prediction of Custom Handwritten Digits: Successfully predicted my own handwritten digit '3' correctly.

* Cost and Accuracy Monitoring: Tracks both loss and accuracy during training.

**Dataset**

The project uses the MNIST dataset, a benchmark dataset of handwritten digits.

Training Set: 60,000 images (28x28 pixels)

Test Set: 10,000 images (28x28 pixels)

